\chapter{Stand der Technik}

Während Kapitel~2 die theoretischen und technischen Grundlagen der 3D-Rekonstruktion erläutert, 
konzentriert sich dieses Kapitel auf den aktuellen Stand der Forschung im Bereich echtzeitfähiger Rekonstruktionssysteme. 
Ziel ist es, bestehende End-to-End-Pipelines sowie ausgewählte Einzelverfahren systematisch zu analysieren 
und deren Relevanz für die in dieser Arbeit entwickelte Architektur zu bewerten. 
Im Fokus stehen Verfahren, die monokulare oder RGB-D-Datenströme in Echtzeit verarbeiten und sich für den Einsatz in modularen Systemarchitekturen eignen.

\section{End-to-End-Rekonstruktionspipelines}

Frühe Echtzeit-Rekonstruktionssysteme wie \textbf{KinectFusion} und \textbf{ElasticFusion}
zeigten erstmals, dass sich Tiefendaten fortlaufend in einem volumetrischen Speicher
akkumulieren lassen, wodurch eine dichte, kamerageführte 3D-Rekonstruktion möglich wird.
Diese Systeme basieren auf klassischen SLAM-Prinzipien, bei denen die Kamerapose in
Echtzeit geschätzt und neue Tiefeninformationen in ein globales TSDF-Volumen integriert werden.
Trotz ihrer Robustheit bleiben sie auf spezielle Sensoren (z.~B.~RGB-D-Kameras) beschränkt
und sind nur eingeschränkt auf monokulare Eingangsdaten übertragbar.

Mit dem Aufkommen neuronaler Verfahren entstanden in den letzten Jahren mehrere
\textbf{End-to-End-Systeme}, die Bildaufnahme, Kameratracking und volumetrische oder
strahlbasierte Rekonstruktion in einem gemeinsamen Netzwerk integrieren.
Beispiele hierfür sind \textbf{NeuralFusion}, \textbf{NICE-SLAM} und \textbf{Co-SLAM}.
Diese Systeme kombinieren dichte Feature-Extraktion, Lern-basierte Tiefenschätzung
und SLAM-Optimierung innerhalb einer einheitlichen Pipeline und erreichen
eine bislang nicht gekannte Konsistenz zwischen lokalen und globalen Karten.
Sie verarbeiten kontinuierliche Kamerastreams und erzeugen fortlaufend aktualisierte 3D-Darstellungen, die bereits während der Kamerabewegung in Echtzeit visualisiert werden können.

Ein früher praxisorientierter Ansatz zur direkten Integration von Rekonstruktionssoftware
in Game-Engines wurde 2017 von \textit{NVIDIA} und \textit{Capturing Reality} vorgestellt~\cite{gdc-photogrammetry-2017}.
Dabei wurde gezeigt, wie sich das Photogrammetrie-Tool \textit{RealityCapture} über ein C++/C\#-SDK
direkt in den Unity-Editor einbinden lässt, um aus gewöhnlichen Kamerabildern in wenigen Minuten
texturierte 3D-Modelle zu erzeugen.
Dieses Konzept einer \emph{Image-to-Unity}-Pipeline markierte einen wichtigen Zwischenschritt
zwischen offline-orientierter Photogrammetrie und modernen, echtzeitfähigen Rekonstruktionssystemen,
die Bildaufnahme, GPU Verarbeitung und Visualisierung zunehmend nahtlos miteinander verbinden.

Gleichzeitig weisen solche Systeme strukturelle Einschränkungen auf:
Sie sind \emph{monolithisch} konzipiert, das heißt Erfassung, Verarbeitung und Ausgabe
sind eng miteinander gekoppelt und kaum austauschbar.
Dies erschwert die Integration in bestehende VR- oder Multi-Modell-Umgebungen,
da Kommunikation und Laufzeitumgebung fest in die jeweilige Architektur eingebettet sind.

\section{Ausgewählte Rekonstruktionsverfahren}

Die in dieser Arbeit integrierten Modelle \textit{NeuralRecon}, \textit{VisFusion}, 
\textit{MASt3R-SLAM} und \textit{SLAM3R} repräsentieren vier moderne \emph{Vertreter} unterschiedlicher Paradigmen der monokularen Echtzeit-3D-Rekonstruktion.
Sie unterscheiden sich hinsichtlich der verwendeten Repräsentation (volumetrisch, hybrid oder implizit),
der Art der Merkmalfusion und der Balance zwischen Genauigkeit und Laufzeit.
Im Folgenden werden ihre zentralen Konzepte und Beiträge zusammengefasst.

\subsection{Volumetrische Verfahren}

\textbf{NeuralRecon} \cite{sun2021neuralrecon}
stellt das erste echtzeitfähige, lernbasierte System zur kohärenten 3D-Rekonstruktion aus monokularen Videos dar.
Anstatt einzelne Tiefenkarten pro Keyframe zu schätzen, 
rekonstruiert es direkt lokale Oberflächen als \textit{Truncated Signed Distance Fields} (TSDF).
Hierzu wird ein rekurrentes 3D-CNN eingesetzt, 
das Bildmerkmale in Sparse-Voxel-Volumes unprojiziert und über eine GRU-basierte Fusionsstufe
zu einem global konsistenten Volumen integriert.
Das Verfahren kombiniert lokale Glättung und globale Formkohärenz
und erreicht so dichte, konsistente Rekonstruktionen in Echtzeit.

\textbf{VisFusion} \cite{gao2023visfusion}
erweitert NeuralRecon um eine explizite Modellierung der Sichtbarkeit bei der Merkmalfusion.
Für jedes Voxel werden Sichtbarkeitsgewichte aus den Paarähnlichkeiten der Projektionsmerkmale verschiedener Ansichten berechnet,
um Okklusionen gezielt zu vermeiden.
Darüber hinaus führt VisFusion eine \textit{ray-based sparsification} ein,
bei der entlang jeder Sehstrahlung mindestens ein Voxel beibehalten wird,
sodass feine Strukturen besser erhalten bleiben.
Ein residual-basiertes TSDF-Refinement verbessert die Oberflächengenauigkeit zusätzlich.
Das Resultat ist ein online-fähiges, visibility-aware Rekonstruktionssystem
mit höherer Detailtreue als klassische TSDF-Fusionen.

\subsection{Hybride SLAM-basierte Verfahren}

\textbf{MASt3R-SLAM} verbindet klassische SLAM-Optimierung mit lernbasiertem Feature-Matching.
Es nutzt die Transformer-basierten Korrespondenz- und Tiefenrepräsentationen des \textit{MASt3R}-Backbones
zur robusten Schätzung von Kameraposen und zur dichten Szenenrekonstruktion.
Durch die Kombination lokaler Pose-Optimierung mit globaler Graph-Konsistenz
werden Rekonstruktionen auch bei schnellen Bewegungen stabil gehalten.
Damit steht MASt3R-SLAM exemplarisch für die jüngste Generation hybrider Verfahren,
die geometrische Präzision mit der Generalisierungsfähigkeit neuronaler Merkmalsmodelle verbinden.

\subsection{Dichte implizite Verfahren}

\textbf{SLAM3R} \cite{liu2025slam3r}
führt ein vollständig differentiierbares, feed-forward-basiertes System zur dichten Echtzeitrekonstruktion ein.
Statt Kameraparameter explizit zu schätzen,
rekonstruiert es für überlappende Videofenster direkt dichte Punktkarten 
über ein \textit{Image-to-Points}-Netzwerk.
Ein zweites Modul (\textit{Local-to-World}) registriert diese lokalen Punktwolken schrittweise
zu einer global konsistenten Szene,
ohne iterative Optimierung oder Pose-Schätzung.
SLAM3R erreicht dadurch hohe Genauigkeit und Vollständigkeit bei über 20 FPS
und repräsentiert die aktuelle Entwicklung hin zu rein lernbasierten, implizit-geometrischen Rekonstruktionssystemen.

\section{Begründung der Modellwahl}

Die Modellwahl basiert auf dem Ziel,
unterschiedliche methodische Ansätze der Echtzeit-3D-Rekonstruktion 
innerhalb einer einheitlichen Architektur vergleichend zu evaluieren.
Die vier ausgewählten Verfahren decken komplementäre Paradigmen ab
und sind allesamt quelloffen, GPU-beschleunigt und streamingfähig,
was ihre Integration in eine containerisierte Umgebung ermöglicht.

\textbf{NeuralRecon} und \textbf{VisFusion} bilden die Referenzgruppe der volumetrischen Verfahren.
Sie erlauben eine konsistente, speicherbewusste TSDF-Fusion
und dienen als stabile Baseline für Echtzeitfähigkeit und Oberflächenkohärenz.
VisFusion ergänzt dabei NeuralRecon um eine explizite Behandlung von Sichtbarkeit und Okklusion.

\textbf{MASt3R-SLAM} repräsentiert den hybriden Übergang zwischen klassischen SLAM-Systemen
und lernbasierten Korrespondenzmodellen.
Seine Integration ermöglicht die Untersuchung,
wie transformerbasierte Feature-Extraktion die Robustheit in Echtzeitszenarien beeinflusst.

\textbf{SLAM3R} schließlich steht für das aktuelle Paradigma implizit-geometrischer Punktrekonstruktion.
Es verzichtet vollständig auf Pose-Optimierung und vereinfacht den Pipeline-Aufbau erheblich,
wodurch es besonders relevant für modulare, containerisierte Systeme wird.

Durch die Einbettung dieser vier Modelle in eine einheitliche Backend-Struktur
kann deren Leistungsfähigkeit unter identischen Bedingungen verglichen werden.
Damit wird eine systematische Analyse von Genauigkeit, Stabilität und Integrationsaufwand ermöglicht,
die über isolierte Modellbenchmarks hinausgeht
und unmittelbare Rückschlüsse für den praktischen Einsatz in Echtzeit-VR-Umgebungen zulässt.

\section{Zwischenfazit}

Zusammenfassend zeigt der aktuelle Stand der Technik, dass moderne Rekonstruktionssysteme
bereits beeindruckende Echtzeitleistungen erzielen. Dennoch bleiben bestehende Pipelines
meist monolithisch aufgebaut und schwer in externe Anwendungen integrierbar.
Das in dieser Arbeit entwickelte System \textit{RTReconstruct} adressiert diese Lücke, indem es
eine containerisierte, modellunabhängige Plattform bereitstellt, die verschiedene Verfahren
über standardisierte Schnittstellen miteinander verbindet.

Das folgende Kapitel beschreibt die daraus abgeleitete \textit{Systemkonzeption}.
Es definiert die funktionalen und nicht-funktionalen Anforderungen, erläutert den architektonischen
Aufbau und zeigt, wie Backend, Frontend und Kommunikationsschichten zu einem konsistenten
Gesamtsystem integriert werden.