\chapter{Einleitung}

\section{Motivation}

Moderne Virtual-Reality-Systeme erlauben dank präziser Hand-, Körper- und Blickerfassung eine zunehmend natürliche Interaktion. Dennoch basieren viele VR-Erfahrungen weiterhin auf künstlich konstruierten Szenen, die nur begrenzt an die reale Umgebung der Nutzenden anschließen. Für Anwendungsfelder wie kollaboratives Arbeiten, simulationsbasiertes Lernen oder räumliche Analysewerkzeuge ist dies ein wesentlicher Nachteil, da dort virtuelle Räume idealerweise Bezug zur physischen Umgebung haben sollten und eine enge Verzahnung zwischen digitaler und realer Welt benötigt wird. 

Ein zentrales Element solcher immersiven und interaktiven VR-Erfahrungen ist daher die Fähigkeit, reale physische Umgebungen digital abzubilden und in das virtuelle Erlebnis einzubetten. Virtuelle Räume wirken besonders glaubwürdig, wenn sie aus realen Szenen abgeleitet sind oder diese zumindest in ihrer Struktur angemessen widerspiegeln. Für viele praktische Anwendungsszenarien bietet dies erhebliche Vorteile: Räume können spontan erfasst, gemeinsam analysiert oder für kollaborative Aufgaben genutzt werden, ohne dass zuvor manuelle Modellierungsprozesse notwendig sind.

Die Rekonstruktion physischer Umgebungen in Form dreidimensionaler Szenenmodelle stellt aus diesem Grund einen wesentlichen Baustein für die nächste Generation interaktiver VR-Systeme dar. Klassische Photogrammetrie liefert zwar hochauflösende Resultate, erfordert jedoch umfangreiche Bildaufnahmen und lange Verarbeitungszeiten und ist damit für dynamische oder interaktive VR-Anwendungen ungeeignet.

In den letzten Jahren wurden daher vermehrt Verfahren entwickelt, die fortlaufende RGB-Videodaten nutzen, um die Geometrie einer Szene sukzessive zu rekonstruieren. Besonders monokulare Verfahren sind für VR dabei von zentraler Bedeutung. Im Gegensatz zu Tiefensensoren oder Mehrkamera-Setups benötigen sie keine zusätzliche Hardware und können direkt auf die Frontkameras moderner VR-Headsets zurückgreifen, die typischerweise genau solche kontinuierlichen RGB-Bildströme liefern.

Obwohl monokulare Rekonstruktionsverfahren grundsätzlich gut zu den Sensoren moderner VR-Headsets passen, ist ihre praktische Einbindung in bestehende Anwendungen bislang kaum etabliert. Viele aktuelle Modelle werden in isolierten Forschungskontexten entwickelt und bringen eigene Laufzeitumgebungen, Frameworks und Datenpipelines mit, die selten auf den Einsatz in interaktiven Systemen ausgelegt sind. VR-Anwendungen benötigen jedoch einen stabilen und klar strukturierten Datenfluss, der kontinuierlich wachsende Szenenmodelle verlässlich bereitstellt und eine nahtlose Integration in das Frontend ermöglicht. Eine modulare Architektur, die heterogene Rekonstruktionsverfahren kapselt, vereinheitlicht und für VR-Umgebungen nutzbar macht, ist in der Forschung bislang nur unzureichend adressiert. Genau an dieser Stelle setzt die vorliegende Arbeit an.

\section{Zielsetzung}

Ziel dieser Arbeit ist die Konzeption, Implementierung und Evaluation eines modularen Systems zur Echtzeit-3D-Rekonstruktion in einer bestehenden VR-Umgebung. Im Mittelpunkt steht nicht die Verbesserung einzelner Rekonstruktionsmodelle, sondern die Entwicklung einer skalierbaren Integrationsarchitektur, die unterschiedliche Verfahren kapselt und über eine standardisierte Schnittstelle mit einem Unity-basierten VR-Frontend kommuniziert.

Als Zielumgebung dient das Va.Si.Li-Lab des Text Technology Lab der Goethe-Universität Frankfurt, eine mehrbenutzerfähige VR-Plattform für simulationsbasierte Lern- und Forschungsszenarien. Das Va.Si.Li-Lab bietet sich besonders an, da es zwar eine modulare, erweiterbare Infrastruktur bereitstellt, jedoch bislang keine Möglichkeit zur dynamischen 3D-Rekonstruktion realer Umgebungen beinhaltet. Die geplante Architektur soll ermöglichen, verschiedene rekonstruktive Ansätze unter identischen Bedingungen zu betreiben, auszutauschen und systematisch zu evaluieren.

Aus dieser Zielsetzung ergibt sich folgende Forschungsfrage:

\vspace{0.6cm}
\begin{center}
    \textit{Wie gut eignet sich eine modulare, containerisierte Systemarchitektur zur Integration verschiedener Echtzeit-3D-Rekonstruktionsverfahren in eine bestehende Virtual-Reality-Umgebung?}
\end{center}

\section{Aufbau der Arbeit}

Zur Beantwortung der Forschungsfrage wird ein modulares System mit Unity-Frontend, containerisiertem Backend und standardisierter Schnittstelle entwickelt, in das Va.Si.Li-Lab integriert und experimentell evaluiert. Die Arbeit gliedert sich wie folgt:

Kapitel~2 behandelt die theoretischen und technischen Grundlagen und führt in Konzepte der Virtual Reality, Verfahren der 3D-Rekonstruktion sowie relevante Systemtechnologien wie Containerisierung und Datenstromverarbeitung ein. Kapitel~3 stellt den aktuellen Stand der Technik vor und analysiert bestehende End-to-End-Rekonstruktionssysteme sowie aktuelle monokulare Rekonstruktionsverfahren. Kapitel~4 beschreibt die Konzeption der modularen Systemarchitektur, während Kapitel~5 die Implementierung der Backend- und Frontend-Komponenten im Detail erläutert. Kapitel~6 präsentiert die experimentelle Evaluierung einschließlich Testaufbau, Messmethodik und Analyse der Ergebnisse - im Fokus stehen dabei Latenz, Durchsatz, Stabilität und Rekonstruktionsqualität unter realitätsnahen Bedingungen. Kapitel~7 schließt die Arbeit mit einer Zusammenfassung, reflektiert Limitationen und gibt einen Ausblick auf zukünftige Erweiterungen.